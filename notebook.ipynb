{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-6c9b62', 'object': 'chat.completion', 'created': 1717847162, 'model': 'lit', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': ' ', 'name': None, 'tool_calls': [{'id': 'call_4fz1q-qqRiyD7RR2v0gThQ', 'type': 'function', 'function': {'name': 'get_current_weather', 'arguments': '{\"location\": \"Paris, France\", \"unit\": \"celsius\"}'}}], 'tool_call_id': None}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 0, 'total_tokens': 0, 'completion_tokens': 0}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://127.0.0.1:8000/v1/chat/completions\",\n",
    "    json={\n",
    "        \"model\": \"lit\",\n",
    "        \"stream\": False,  # You can stream chunked response by setting this True\n",
    "        \"tools\": [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_current_weather\",\n",
    "                    \"description\": \"Get the current weather in a given location\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                            },\n",
    "                            \"unit\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\"location\"],\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"What's the weather like in Paris/London?\"}],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# specify how to quantize the model\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "        )\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\", device_map=\"auto\", quantization_config=quantization_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "req temperature=0.7 top_p=1.0 max_tokens=None random_seed=None model=None messages=[UserMessage(role=<Roles.user: 'user'>, content=\"What's the weather like in Paris?\")] response_format=ResponseFormat(type='text') tools=[Tool(type='function', function=Function(name='get_current_weather', description='Get the current weather in a given location', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g. San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit']}}, 'required': ['location']}))] tool_choice='auto'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,     6,  1501,  7567,  1891,  2032,  1113,  3396,  1316,  1113,\n",
       "           3396,  2032, 10598,  1629,  2032,  1113,  1295, 29498,  3790, 29498,\n",
       "           1537,  1991,  1316,  1113,  7286,  2032,  1113,  2226,  1040,  2636,\n",
       "           8854,  1065,  1032,  2846,  5491,  1316,  1113, 12206,  2032, 10598,\n",
       "           1891,  2032,  1113,  3582,  1316,  1113, 11491,  2032, 10598,  3501,\n",
       "           2032, 10598,  1891,  2032,  1113,  2195,  1316,  1113,  7286,  2032,\n",
       "           1113,  1782,  3758,  1072,  2433, 29493,  1085, 29491, 29489, 29491,\n",
       "           4420, 10454, 29493, 10229,  8474,  1113,  6074,  2032, 10598,  1891,\n",
       "           2032,  1113,  2195,  1316,  1113, 10825,  2032,  8135, 29485,  1958,\n",
       "           3938,  1316,  1113, 29490, 19425, 13075,  3010, 11549,  1113, 11661,\n",
       "           2032,  8135,  3501,  3010,  1743, 10925,     7,     3,  2592, 29510,\n",
       "          29481,  1040,  8854,  1505,  1065,  6233, 29572,     4]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from pathlib import Path\n",
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "\n",
    "mistral_models_path = Path.home().joinpath(\"mistral_models\", \"7B-Instruct-v0.3\")\n",
    "mistral_tokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tokenizer.model.v3\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Paris?\"}\n",
    "]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "completion_request = ChatCompletionRequest(messages=messages, tools=tools)\n",
    "print(\"req\", completion_request)\n",
    "# text = mistral_tokenizer.encode_chat_completion(completion_request).text\n",
    "tokens = mistral_tokenizer.encode_chat_completion(completion_request).tokens\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "input_ids = torch.tensor([tokens]).to(device)\n",
    "\n",
    "# Create attention mask where 1s indicate real tokens and 0s indicate padding\n",
    "attention_mask = torch.ones_like(input_ids).to(device)\n",
    "\n",
    "# Set the padding tokens to 0\n",
    "# attention_mask[input_ids == tokenizer.pad_token_id] = 0\n",
    "\n",
    "model_inputs = {\n",
    "    \"input_ids\":input_ids,\n",
    "    \"attention_mask\": attention_mask\n",
    "}\n",
    "\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your Hugging Face token as an environment variable\n",
    "os.environ['HF_API_TOKEN'] = 'token_here'\n",
    "\n",
    "# Use the token to login\n",
    "from huggingface_hub import login\n",
    "login(token=os.environ['HF_API_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOOL_CALLS] [{\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"Paris\", \"unit\": \"celsius\"}}]</s>"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from transformers import TextIteratorStreamer\n",
    "\n",
    "streamer = TextIteratorStreamer(\n",
    "    tokenizer,\n",
    "    skip_prompt=True,\n",
    "    skip_special_tokens=False,\n",
    "    clean_up_tokenization_spaces=True,\n",
    ")\n",
    "\n",
    "# Run the generation in a separate thread, \n",
    "# so that we can fetch the generated text in a non-blocking way.\n",
    "generation_kwargs = dict(\n",
    "    model_inputs,\n",
    "    streamer=streamer,\n",
    "    max_new_tokens=1000,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "thread.start()\n",
    "for text in streamer:\n",
    "    print(text,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_1XWihodYRvuvvTrixLZOtA',\n",
       "  'function': {'arguments': '{\"location\": \"Paris, France\", \"unit\": \"celsius\"}',\n",
       "   'name': 'get_current_weather'},\n",
       "  'type': 'function'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import extract_tool_calls_from_buffer\n",
    "buffer=\"\"\"[TOOL_CALLS] [{\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"Paris, France\", \"unit\": \"celsius\"}}]\n",
    "\n",
    "For Paris, France:\n",
    "\n",
    "[{\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"London, UK\", \"unit\": \"celsius\"}}]\n",
    "\n",
    "For London, UK:\n",
    "\n",
    "(Wait for the responses)\n",
    "\n",
    "(Assuming the responses are as follows:)\n",
    "\n",
    "For Paris, France:\n",
    "{\"temperature\": 15, \"conditions\": \"Partly cloudy\"}\n",
    "\n",
    "For London, UK:\n",
    "{\"temperature\": 12, \"conditions\": \"Cloudy\"}\n",
    "\n",
    "The current weather in Paris, France is Partly cloudy with a temperature of 15 degrees Celsius.\n",
    "The current weather in London, UK is Cloudy with a temperature of 12 degrees Celsius.</s>\n",
    "\"\"\"\n",
    "extract_tool_calls_from_buffer(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, name=None, tool_call_id=None)\n",
      "ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=None, id='call_Qws9ZdQPSyGie6Vw4RrvyA', function=ChoiceDeltaToolCallFunction(arguments='{\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}', name='get_current_weather'), type='function')], name=None, tool_call_id=None)\n",
      "ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None, name=None, tool_call_id=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=\"http://127.0.0.1:8000/v1\", api_key=\"lit\")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    tools=tools,\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta or \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='                                    ', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_YpH8rS3RSIKxsKKEbgyAUA', function=Function(arguments='{\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}', name='get_current_weather'), type='function')], name=None, tool_call_id=None))\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "          },\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "      },\n",
    "    }\n",
    "  }\n",
    "]\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=messages,\n",
    "  tools=tools,\n",
    "  tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "print(completion.choices[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
